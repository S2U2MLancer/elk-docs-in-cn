# Anatomy of an analyzer

无论是内置的还是自定义的分析器, 都只是一个包含三个低级构建块的包: 
- 字符过滤器(character filters)
- 标记器(tokenizers)
- 标记过滤器(token filters)

内置分析仪将这些构建块预先打包成适合不同语言和文本类型的分析仪。
Elasticsearch还公开了各个构建块，以便它们可以组合以定义新的自定义分析器。

## Character filtersedit

字符过滤器将原始文本作为字符流接收，并可通过添加，删除或更改字符来转换流。 
例如，可以使用字符过滤器将印度语-阿拉伯数字（٠‎١٢٣٤٥٦٧٨‎٩）
转换为阿拉伯语-拉丁语等价物（0123456789），
或者从流中去除`<b>`等HTML元素。

分析器可以具有零个或多个字符过滤器，这些过滤器按顺序应用。

## Tokenizer

标记生成器接收字符流，将其分解为单个标记（通常是单个单词），并输出标记流。
例如，只要看到任何空格，空格标记器就会将文本分成标记。
它会将文本“Quick brown fox!”转换为[Quick, brown, fox!].

## Token filters
